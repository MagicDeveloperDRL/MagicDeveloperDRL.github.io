---

layout:     post
title:      「深度学习」经典文献整理
subtitle:   深度学习相关
date:       2021-12-04
author:     MRL Liu
header-img: img/the-first.png
catalog: True
tags:
    - 深度学习
---

​		本博客是作者阅读论文过程中整理的经典论文的笔记。

# 摘要

​       本文提出了一种新的无监督的图像到图像的转换方法，该方法以端到端的方式结合了一个新的==注意力模块==和一个新的可学习的==归一化函数==。

​		==注意力模块==依据`辅助分类器`获得的`注意力图`，引导本文模型关注和区分source domain和target domain中更重要的区域。与以前基于注意力的方法不能处理target 之间的几何变化不同，本文模型可以转换需要整体变化的图像和较大形状变化的图像。

​		此外，本文新的==AdaLIN函数==（Adap，activelayer Instance Normalization）有助于本文的注意力引导模型在数据集上通过学习到的参数灵活控制形状和纹理的变化。实验结果表明，与现有的具有固定网络结构和超参数的先进模型相比，该方法具有优越性。

## 深度学习框架

| 年份作者出处             | 主要贡献    | 论文题目                                 | 相关特点 |
| ------------------------ | ----------- | ---------------------------------------- | -------- |
| 2017年的Paszke等人，NIPS | Pytorch框架 | 《Automatic differentiation in pytorch》 | 经典框架 |
|                          |             |                                          |          |

## 网络类型

| 年份作者出处                 | 主要贡献 | 论文题目                   | 相关特点     |
| ---------------------------- | -------- | -------------------------- | ------------ |
| Hochreiter和Schmidhuber 1997 | LSTM网络 | 《Long short-term memory》 | 经典网络类型 |
|                              |          |                            |              |

## 标准化

| 年份作者出处                   | 主要贡献                                                     | 论文题目                                                     | 相关特点                                                     |
| ------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 2015年 ICML                    | 批量标准化（BN）                                             | 《Batch normalization: Accelerating deep network training by reducing internal covariate shift》 | 一般添加在激活层之前，其作用是加快模型训练时的收敛速度，使得模型训练过程更加稳定，同时可能提升精度，避免梯度爆炸或者梯度消失，并且起到一定的正则化作用，几乎代替了Dropout，其核心公式计算一个批次所有样本的均值和方差。在目标检测领域已经成为标配，但是BN不适合RNN等动态网络，在BatchSize较小时效果不好 |
| 2016年                         | 层标准化（LN）                                               | 《Layer Normalization》                                      | LN解决了BN不适合RNN等动态网络和较小BatchSize的问题，但是在BN和LN都能使用的场景中，BN的效果一般优于LN，原因是基于不同数据，BN同一特征得到的归一化特征更不容易损失信息。LN在分类问题上的表现可能比较差一点，其核心公式计算一个样本所有通道的内容。该论文没有发表 |
| 2016年                         | 实例标准化（IN）                                             | 《Instance Normalization: The Missing Ingredient for Fast Stylization》 | 其核心公式计算一个样本的一个通道的内容，所以适合用于对单个像素信息比较敏感的图像风格迁移任务，在GAN中使用比较多，在图像样式转换中比BN和LN更常用，该论文没有发表，但是经过了无数研究实验验证有效 |
| 2018年ECCV，                   | 组标准化（GN）                                               | 《Group normalization》                                      | GN称其解决了BN式归一化对batch size依赖的影响，用于物体检测和语义分割等batch size很小的任务场景中。 |
| 2017年ICLR                     | 条件实例标准化模块（CIN）                                    | 《A learned representation for artistic style》              | 其在训练中学习不同的仿射变换参数![[公式]](https://www.zhihu.com/equation?tex=%5Cgamma) 和 ![[公式]](https://www.zhihu.com/equation?tex=%5Cbeta)，对于同一张content image，同一个迁移网络，使用相同的卷积层参数，使用不同的![[公式]](https://www.zhihu.com/equation?tex=%5Cgamma%5E%7Bs%7D) 和 ![[公式]](https://www.zhihu.com/equation?tex=%5Cbeta%5E%7Bs%7D) 对，可以得到不同风格的迁移结果。 |
| 2017年，Huang & Belongie，ICCV | 自适应实例标准化模块（AdaIN）<font color=Red>本文重点参考</font> | 《Arbitrary style transfer in real-time with adaptive instance normalization》 | 将内容图像（content image）特征的均值和方差对齐到风格图像（style image）的均值和方差，其论文证明了图像特征图的均值和方差就代表着图像的风格，在之前的BN，IN，CIN中，网络会学习仿射变换参数![[公式]](https://www.zhihu.com/equation?tex=%5Cgamma) 和 ![[公式]](https://www.zhihu.com/equation?tex=%5Cbeta)，作者提出的AdaIN则无需学习这两个参数，直接用style image的特征的均值和标准差代替这两个参数， |
| 2018年，Miyato等人             | 光谱标准化（SN）                                             | 《Spectral Normalization for Generative Adversarial Networks》 | 在归一化层中使用仿射变换参数$\gamma$和$\beta$并结合归一化函数 |
| 2018年，Nam& Kim，ANIPS        | 批量实例标准化模块（BIN）<font color=Red>本文重点参考</font> | 《Batch-instance normalization for adaptively style-invariant neural networks》 | 在归一化层中使用仿射变换参数$\gamma$和$\beta$并结合归一化函数 |
| 2020年ICLR                     | 自适应层实例标准化模块（AdaLIN）                             | 《U-GAT-IT: Unsupervised ganerative attentional networks with adaptive layer-instance normalization for image-to-image translation》 | 用于自适应地选择IN和LN之间的适当比率。                       |

## 优化器

| 年份作者出处        | 主要贡献    | 论文题目                                       | 相关特点             |
| ------------------- | ----------- | ---------------------------------------------- | -------------------- |
| Kingma和Adam 2014年 | Adam优化器  | 《Adam: A Method for Stochastic Optimization》 | 几乎是最常见的优化器 |
|                     | AdamW优化器 |                                                |                      |

## 激活函数

| 年份作者出处      | 主要贡献           | 论文题目                                       | 相关特点               |
| ----------------- | ------------------ | ---------------------------------------------- | ---------------------- |
| Nair和Hinton 2010 | ReLu激活函数       | 《Adam: A Method for Stochastic Optimization》 | 几乎是最常见的激活函数 |
|                   | leaky-ReLU激活函数 |                                                |                        |

## GAN网络

| 提出年份    | 模型名称   | 相关论文                                                     | 主要工作 |
| ----------- | ---------- | ------------------------------------------------------------ | -------- |
| 2017年ICCV  | CycleGAN   | 《Unpaired image-to-image translation using cycle-consistent adversarial networks》 |          |
| 2017年ANIPS | UNIT       | 《Unsupervised image-to-image translation networks》         |          |
| 2018年ECCV  | MUNIT      | 《Multimodal unsupervised image-toimage translation》        |          |
| 2018年ECCV  | DRIT       | 《Diverse image-to-image translation via disentangled representations》 |          |
| 2018年ANIPS | AGGAN      | 《Unsupervised attention-guided image-to-image translation》 |          |
| 2018年CVPR  | CartoonGAN | 《Cartoongan: Generative adversarial networks for photo cartoonization》 |          |

## 注意力机制

| 年份会议                     | 主要贡献                                          | 论文题目                                                     | 相关特点                                                     |
| ---------------------------- | ------------------------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 2014年的ANIPS，Goodfello等人 | GAN                                               | 《 Generative adversarial nets》                             |                                                              |
| **图像生成的相关研究**       |                                                   |                                                              |                                                              |
| 2017年的ICML，Arjovsky等人   | WGAN                                              | 《Wasserstein generative adversarial networks》              |                                                              |
| 2017年的，Berthelot等人      |                                                   | 《Began: Boundary equilibrium generative adversarial networks》 |                                                              |
| 2018年的ICLR，Karras等人     |                                                   | 《Progressive growing of gans for improved quality, stability,and variation》 |                                                              |
| 2017年的ICLR，Zhao等人       |                                                   | 《Energy-based generative adversarial networks》             |                                                              |
| 2017年的ICCV，Mao等人        |                                                   | 《Least squares generative adversarial networks》            |                                                              |
| **图像修复的相关研究**       |                                                   |                                                              |                                                              |
| 2017年的TOG，Iizuka等人      |                                                   | 《Globally and locally consistent image completion》         |                                                              |
| **图像转换的相关研究**       |                                                   |                                                              |                                                              |
| 2017年的CVPR，Isola等人      | CGAN                                              | 《Image-to-image translation with conditional adversarial networks》 | 提出了一个基于条件GAN的图像到图像转换统一框架。              |
|                              |                                                   |                                                              |                                                              |
| 2017年的ICCV，Zhu等          | CycleGAN（<font color=Red>本文实验基线</font>）   | 《Unpaired image-to-image translation using cycle-consistent adversarial networks》 | 首次提出了循环一致性损失，以实施一对一映射                   |
| 2017年的ANIPS，Liu等人       | UNIT（<font color=Red>本文实验基线</font>）       | 《Unsupervised image-to-image translation networks》         | 假设一个共享的潜在空间来处理无监督的图像翻译。然而，只有当两个域具有相似的模式时，这种方法才能很好地执行。 |
| 2018年的CVPR，Wang等人       |                                                   | 《High-resolution image synthesis and semantic manipulation with conditional gans》 | 提出了pix2pix的高分辨率版本                                  |
| 2018年的ECCV，Huang等人      | MUNIT（<font color=Red>本文实验基线</font>）      | 《Multimodal unsupervised image-to-image translation》       | 通过将图像分解为域不变的内容代码和捕获特定于域的属性的样式代码，可以扩展到多对多映射。MUNIT综合分离的内容和风格生成最终图像，其中图像质量通过使用自适应实例归一化AdamIN得到改善。 |
| 2018年的CVPR，Choi等人       |                                                   | 《Stargan: Unified generative adversarial networks for multi-domain image-to-image translation》 |                                                              |
| 2018年ECCV，Lee 等人         | DRIT（<font color=Red>本文实验基线</font>）       | 《Diverse image-to-image translation via disentangled representations》 | 将图像分解为内容和风格，从而实现多对多映射。唯一的区别是，使用权重共享和内容鉴别器（作为辅助分类器）在两个域之间共享内容空间。 |
| 2018年ANIPS，Mejjati等人     | AGGAN（<font color=Red>本文实验基线</font>）      | 《Unsupervised attention-guided image-to-image translation》 | 通过使用注意力机制区分前、后和背景，提高了图像转换的性能。然而，AGGA中的注意模块无法帮助变换图像中对象的形状。 |
| 2018年CVPR，Chen等人         | CartoonGAN（<font color=Red>本文实验基线</font>） | 《Cartoongan: Generative adversarial networks for photo cartoonization》 | 在动画风格翻译方面表现良好，但它只改变图像中线条的颜色、色调和厚度。因此，它不适合图像中的形状变化。 |
